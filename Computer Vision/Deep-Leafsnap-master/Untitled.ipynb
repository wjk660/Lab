{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--resume PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\mi919\\AppData\\Roaming\\jupyter\\runtime\\kernel-5df81e05-925a-40c5-bfab-03f9d87c1209.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.misc\n",
    "import shutil\n",
    "import time\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import utils\n",
    "\n",
    "from PIL import Image\n",
    "from averagemeter import *\n",
    "from models import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import sampler\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# GLOBAL CONSTANTS\n",
    "INPUT_SIZE = 224\n",
    "NUM_CLASSES = 185\n",
    "NUM_EPOCHS = 35\n",
    "LEARNING_RATE = 1e-1\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "best_prec1 = 0\n",
    "classes = []\n",
    "\n",
    "# ARGS Parser\n",
    "parser = argparse.ArgumentParser(description='PyTorch LeafSnap Training')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Test method\n",
    "def test(test_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    class_correct = list(0. for i in range(185))\n",
    "    class_total = list(0. for i in range(185))\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(test_loader):\n",
    "        if USE_CUDA:\n",
    "            input = input.cuda(async=True)\n",
    "            target = target.cuda(async=True)\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        print('\\nGroundTruth: ', ' '.join('%5s' % classes[target_var[0][0]]))\n",
    "        print('Predicted: ', ' '.join('%5s' % classes[predicted[0][0]]))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                      i, len(test_loader), batch_time=batch_time, loss=losses,\n",
    "                      top1=top1, top5=top5))\n",
    "\n",
    "    print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "          .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "print('\\n[INFO] Creating Model')\n",
    "model = models.resnet101(pretrained=False)\n",
    "model.fc = nn.Linear(2048, 185)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if USE_CUDA:\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    criterion = criterion.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "\n",
    "checkpoint = torch.load('model_best.pth.tar')\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "print('\\n[INFO] Model Architecture: \\n{}'.format(model))\n",
    "\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "print('\\n[INFO] Reading Training and Testing Dataset')\n",
    "traindir = os.path.join('dataset', 'train')\n",
    "testdir = os.path.join('dataset', 'test')\n",
    "iphonedir = os.path.join('dataset', 'iphone')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "data_train = datasets.ImageFolder(traindir, transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize]))\n",
    "data_test = datasets.ImageFolder(testdir, transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize]))\n",
    "iphone_test = datasets.ImageFolder(iphonedir, transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize]))\n",
    "classes = data_train.classes\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=64, shuffle=False, num_workers=2)\n",
    "iphone_loader = torch.utils.data.DataLoader(iphone_test, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "print('\\n[INFO] Testing on Original Test Data Started')\n",
    "prec1 = test(test_loader, model, criterion)\n",
    "print(prec1)\n",
    "\n",
    "print('\\n[INFO] Testing on iPhone Test Data Started')\n",
    "prec1 = test(iphone_loader, model, criterion)\n",
    "print(prec1)\n",
    "\n",
    "print('\\n[DONE]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--resume PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\mi919\\AppData\\Roaming\\jupyter\\runtime\\kernel-d13cd2ac-d8ed-4871-80b5-b2678282a23e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
