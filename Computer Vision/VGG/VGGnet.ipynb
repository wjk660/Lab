{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积函数：\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "# 定义池化函数：\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# 定义VGG结构：\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture  x.shape:(128,128,3)\n",
    "    x = tf.reshape(x, shape=[-1, 128, 128, 3])\n",
    " \n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    pool1 = maxpool2d(conv2, k=2)\n",
    "    print(pool1.shape) #(64,64,64)\n",
    " \n",
    "    # Convolution Layer\n",
    "    conv3 = conv2d(pool1, weights['wc3'], biases['bc3'])\n",
    "    conv4 = conv2d(conv3, weights['wc4'], biases['bc4'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    pool2 = maxpool2d(conv4, k=2)\n",
    "    print(pool2.shape) #(32,32,128)\n",
    " \n",
    "    # Convolution Layer\n",
    "    conv5 = conv2d(pool2, weights['wc5'], biases['bc5'])\n",
    "    conv6 = conv2d(conv5, weights['wc6'], biases['bc6'])\n",
    "    conv7 = conv2d(conv6, weights['wc7'], biases['bc7'])\n",
    "    # Max Pooling\n",
    "    pool3 = maxpool2d(conv7, k=2)\n",
    "    print(pool3.shape) #(16,16,256)\n",
    " \n",
    "    # Convolution Layer\n",
    "    conv8 = conv2d(pool3, weights['wc8'], biases['bc8'])\n",
    "    conv9 = conv2d(conv8, weights['wc9'], biases['bc9'])\n",
    "    conv10 = conv2d(conv9, weights['wc10'], biases['bc10'])\n",
    "    # Max Pooling\n",
    "    pool4 = maxpool2d(conv10, k=2)\n",
    "    print(pool4.shape) #(8,8,512)\n",
    " \n",
    "    conv11 = conv2d(pool4, weights['wc11'], biases['bc11'])\n",
    "    conv12 = conv2d(conv11, weights['wc12'], biases['bc12'])\n",
    "    conv13 = conv2d(conv12, weights['wc13'], biases['bc13'])\n",
    "    # Max Pooling\n",
    "    pool5 = maxpool2d(conv13, k=2)\n",
    "    print(pool5.shape) #(4,4,512)\n",
    " \n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(pool5, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    " \n",
    "    #fc2 = tf.reshape(fc1, [-1, weights['wd2'].get_shape().as_list()[0]])\n",
    "    fc2 = tf.add(tf.matmul(fc1, weights['wd2']), biases['bd2'])\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    # Apply Dropout\n",
    "    fc2 = tf.nn.dropout(fc2, dropout)\n",
    "    '''\n",
    "    fc3 = tf.reshape(fc2, [-1, weights['out'].get_shape().as_list()[0]])\n",
    "    fc3 = tf.add(tf.matmul(fc2, weights['out']), biases['bd2'])\n",
    "    fc3 = tf.nn.relu(fc2)\n",
    "    '''\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc2, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "\n",
    "# 定义权重：\n",
    "weights = {\n",
    "    # 3x3 conv, 3 input, 24 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([3, 3, 3, 64])),\n",
    "    'wc2': tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    " \n",
    "    'wc3': tf.Variable(tf.random_normal([3, 3, 64, 128])),\n",
    "    'wc4': tf.Variable(tf.random_normal([3, 3, 128, 128])),\n",
    " \n",
    "    'wc5': tf.Variable(tf.random_normal([3, 3, 128, 256])),\n",
    "    'wc6': tf.Variable(tf.random_normal([3, 3, 256, 256])),\n",
    "    'wc7': tf.Variable(tf.random_normal([3, 3, 256, 256])),\n",
    " \n",
    "    'wc8': tf.Variable(tf.random_normal([3, 3, 256, 512])),\n",
    "    'wc9': tf.Variable(tf.random_normal([3, 3, 512, 512])),\n",
    "    'wc10': tf.Variable(tf.random_normal([3, 3, 512, 512])),\n",
    " \n",
    "    'wc11': tf.Variable(tf.random_normal([3, 3, 512, 512])),\n",
    "    'wc12': tf.Variable(tf.random_normal([3, 3, 512, 512])),\n",
    "    'wc13': tf.Variable(tf.random_normal([3, 3, 512, 512])),\n",
    "    # fully connected, 32*32*96 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([4*4*512, 1024])),\n",
    "    'wd2': tf.Variable(tf.random_normal([1024, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, 10]))\n",
    "    \n",
    "    \n",
    "# 定义偏置：\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([64])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bc3': tf.Variable(tf.random_normal([128])),\n",
    "    'bc4': tf.Variable(tf.random_normal([128])),\n",
    "    'bc5': tf.Variable(tf.random_normal([256])),\n",
    "    'bc6': tf.Variable(tf.random_normal([256])),\n",
    "    'bc7': tf.Variable(tf.random_normal([256])),\n",
    "    'bc8': tf.Variable(tf.random_normal([512])),\n",
    "    'bc9': tf.Variable(tf.random_normal([512])),\n",
    "    'bc10': tf.Variable(tf.random_normal([512])),\n",
    "    'bc11': tf.Variable(tf.random_normal([512])),\n",
    "    'bc12': tf.Variable(tf.random_normal([512])),\n",
    "    'bc13': tf.Variable(tf.random_normal([512])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'bd2': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([10]))\n",
    "    \n",
    "    \n",
    "# 其他参数：\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    " \n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    " \n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    " \n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "saver=tf.train.Saver()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
